# Relevant links from the course

- [Chain-of-Thought Prompting Elicits Reasoning in Large Language Models](https://arxiv.org/abs/2205.11916)
- [Large Language Models are Zero-Shot Reasoners](https://arxiv.org/abs/2205.11916)
- [Auto-CoT](https://github.com/amazon-science/auto-cot)
- [Large Language Models as Optimizers (Take a deep breath)](https://arxiv.org/abs/2309.03409)
- [Generated Knowledge Prompting for Commonsense Reasoning](https://arxiv.org/abs/2110.08387)
- [Tree of Thoughts: Deliberate Problem Solving with Large Language Models](https://arxiv.org/abs/2305.10601)
- [Large Language Model Guided Tree-of-Thought](https://arxiv.org/abs/2305.08291)
- [Using Tree-of-Thought Prompting to boost ChatGPT's reasoning](https://github.com/dave1010/tree-of-thought-prompting)
- [Guiding Large Language Models via Directional Stimulus Prompting](https://arxiv.org/abs/2302.11520)
- [From Sparse to Dense: GPT-4 Summarization with Chain of Density Prompting](https://arxiv.org/abs/2309.04269)
